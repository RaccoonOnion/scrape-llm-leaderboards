import os
import json
import pandas as pd
import traceback

# --- Configuration ---
# Adjust these paths if your files are located elsewhere
CSV_DIR       = "csv"
LIVEBENCH_CSV = os.path.join(CSV_DIR, "livebench.csv")
LMSYS_CSV     = os.path.join(CSV_DIR, "lmsys.csv")
MAPPING_PATH  = "model_mapping_4omini.json" # The mapping file generated by the previous script

# --- Helper Function for Validation ---
def validate_mapping(mapping_data, livebench_models, lmsys_models):
    """
    Validates the entries in the mapping data against the actual model lists.

    Args:
        mapping_data (list): The list of mapping dictionaries loaded from JSON.
        livebench_models (set): A set of unique model names from livebench.csv.
        lmsys_models (set): A set of unique model names from lmsys.csv.

    Returns:
        tuple: A tuple containing (list_of_invalid_entries, total_entries_checked).
    """
    invalid_entries = []
    total_checked = 0

    if not isinstance(mapping_data, list):
        print(f"Error: Mapping data loaded from {MAPPING_PATH} is not a list.")
        return invalid_entries, total_checked

    for index, entry in enumerate(mapping_data):
        total_checked += 1
        is_valid = True
        error_messages = []

        # Basic structure check
        if not isinstance(entry, dict):
            error_messages.append(f"Entry is not a dictionary: {entry}")
            is_valid = False
        else:
            # Key existence check
            required_keys = {"model_livebench", "model_lmsys", "confidence"}
            missing_keys = required_keys - set(entry.keys())
            if missing_keys:
                error_messages.append(f"Missing keys: {', '.join(missing_keys)}")
                is_valid = False # Mark as invalid if keys are missing

            # Proceed with value checks only if keys exist to avoid KeyErrors
            if not missing_keys:
                # Validate 'model_livebench'
                livebench_model = entry.get("model_livebench")
                if livebench_model is None:
                    error_messages.append("'model_livebench' key exists but value is None.")
                    is_valid = False
                # Check against the set only if the model name is not None
                elif livebench_model not in livebench_models:
                    error_messages.append(f"'model_livebench' ('{livebench_model}') not found in {LIVEBENCH_CSV}.")
                    is_valid = False

                # Validate 'model_lmsys'
                lmsys_model = entry.get("model_lmsys")
                # It's okay if lmsys_model is None (null in JSON)
                if lmsys_model is not None and lmsys_model not in lmsys_models:
                    error_messages.append(f"'model_lmsys' ('{lmsys_model}') is not null and not found in {LMSYS_CSV}.")
                    is_valid = False

                # Validate 'confidence'
                confidence = entry.get("confidence")
                if not isinstance(confidence, (int, float)):
                    error_messages.append(f"'confidence' ({confidence}) is not a number.")
                    is_valid = False
                elif not (0.0 <= confidence <= 1.0):
                    error_messages.append(f"'confidence' ({confidence}) is not between 0.0 and 1.0.")
                    is_valid = False

        if not is_valid:
            # Ensure entry data is included even if keys were missing initially
            invalid_entry_data = entry if isinstance(entry, dict) else {"raw_entry": entry}
            invalid_entries.append({"index": index, "entry": invalid_entry_data, "errors": error_messages})

    return invalid_entries, total_checked

# --- Main Execution ---
if __name__ == "__main__":
    print("Starting mapping validation...")

    # 1. Load Mapping File
    try:
        print(f"Loading mapping file: {MAPPING_PATH}")
        with open(MAPPING_PATH, 'r') as f:
            mapping_content = f.read()
            if not mapping_content.strip():
                 print(f"Error: Mapping file '{MAPPING_PATH}' is empty.")
                 exit(1)
            loaded_mapping = json.loads(mapping_content)
        print(f"Successfully loaded mapping file.")
    except FileNotFoundError:
        print(f"Error: Mapping file not found at {MAPPING_PATH}")
        exit(1)
    except json.JSONDecodeError as e:
        print(f"Error: Could not decode JSON from {MAPPING_PATH}. Invalid JSON format: {e}")
        exit(1)
    except Exception as e:
        print(f"An unexpected error occurred while loading {MAPPING_PATH}: {e}")
        traceback.print_exc()
        exit(1)

    # 2. Load CSVs and Extract Model Names
    try:
        print(f"Loading CSV file: {LIVEBENCH_CSV}")
        livebench_df = pd.read_csv(LIVEBENCH_CSV)
        # Use set for efficient lookup, handle potential NaN values explicitly
        livebench_models_set = set(livebench_df["Model"].dropna().unique())
        print(f"Extracted {len(livebench_models_set)} unique models from {LIVEBENCH_CSV}")

        print(f"Loading CSV file: {LMSYS_CSV}")
        lmsys_df = pd.read_csv(LMSYS_CSV)
        lmsys_models_set = set(lmsys_df["model"].dropna().unique())
        print(f"Extracted {len(lmsys_models_set)} unique models from {LMSYS_CSV}")

    except FileNotFoundError as e:
        print(f"Error: CSV file not found: {e}")
        exit(1)
    except KeyError as e:
        print(f"Error: Column {e} not found in one of the CSV files. Check column names ('Model' in livebench, 'model' in lmsys).")
        exit(1)
    except Exception as e:
        print(f"An unexpected error occurred while loading CSVs or extracting model names: {e}")
        traceback.print_exc()
        exit(1)

    # 3. Perform Validation of individual entries
    print("\nValidating mapping entries...")
    invalid_entries, total_checked = validate_mapping(loaded_mapping, livebench_models_set, lmsys_models_set)

    # 4. Report Results
    print("\n--- Validation Report ---")
    print(f"Total entries checked in mapping file: {total_checked}")

    # Report entry-specific errors
    if not invalid_entries:
        print("âœ… All individual mapping entries appear valid.")
    else:
        print(f"ðŸš¨ Found {len(invalid_entries)} invalid individual entries:")
        for invalid in invalid_entries:
            print(f"\n  Entry Index: {invalid['index']}")
            print(f"  Entry Data: {invalid['entry']}")
            print(f"  Errors:")
            for err in invalid['errors']:
                print(f"    - {err}")

    # 5. Perform Coverage Check for livebench models
    print("\n--- Coverage Check ---")
    # Extract all unique 'model_livebench' values from the mapping file
    mapped_livebench_models_set = set()
    if isinstance(loaded_mapping, list):
        for entry in loaded_mapping:
            # Check if entry is a dict and has the key before accessing it
            if isinstance(entry, dict) and "model_livebench" in entry and entry["model_livebench"] is not None:
                 mapped_livebench_models_set.add(entry["model_livebench"])

    # Find models in livebench CSV that are not in the mapping file
    missing_livebench_models = livebench_models_set - mapped_livebench_models_set

    if not missing_livebench_models:
        # Check if the number of mapped models actually matches the number of unique livebench models
        if len(mapped_livebench_models_set) == len(livebench_models_set):
             print(f"âœ… All {len(livebench_models_set)} unique models from {LIVEBENCH_CSV} are present in the mapping file.")
        else:
             # This case might happen if the mapping file contains duplicates or models not in the original CSV
             print(f"âœ… All {len(livebench_models_set)} unique models from {LIVEBENCH_CSV} appear to be covered.")
             print(f"   (Note: Mapping file contains {len(mapped_livebench_models_set)} unique 'model_livebench' values.)")

    else:
        print(f"ðŸš¨ Found {len(missing_livebench_models)} models from {LIVEBENCH_CSV} that are MISSING from the 'model_livebench' values in '{MAPPING_PATH}':")
        # Sort for consistent and readable output
        for model_name in sorted(list(missing_livebench_models)):
            print(f"  - {model_name}")

    print("\nValidation finished.")
